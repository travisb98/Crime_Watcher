{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "a0697a08853843cee7b0067dcaa1e245b3dcd8145de4cf8fef185db7dee63cac"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "import pickle\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "# define the current and previous year\n",
    "current_year = datetime.datetime.now().year\n",
    "last_year = current_year - 1\n",
    "\n",
    "# function that calls api and returns the features for a given year\n",
    "def callAndStore(year):\n",
    "    url = f'https://services.arcgis.com/afSMGVsC7QlRK1kZ/arcgis/rest/services/Police_Incidents_{year}/FeatureServer/0/query?where=1%3D1&outFields=reportedDateTime,offense,description,centerLong,centerLat&outSR=4326&f=json'\n",
    "    # make api request\n",
    "    response = requests.get(url).json()\n",
    "\n",
    "    features = [x for x in response['features']]\n",
    "\n",
    "    return features\n",
    "\n",
    "crime_list=[]\n",
    "\n",
    "# for all features in the current and prior year.....\n",
    "for crime in (callAndStore(current_year)+callAndStore(last_year)):\n",
    "    clean_crime={\n",
    "        'date':datetime.datetime.fromtimestamp(crime['attributes']['reportedDateTime']/1000).strftime(\"%m/%d/%Y\"),\n",
    "        'time':datetime.datetime.fromtimestamp(crime['attributes']['reportedDateTime']/1000).strftime(\"%H:%M:%S\"),\n",
    "        'centerLong': crime['attributes']['centerLong'],\n",
    "        'centerLat':crime['attributes']['centerLat'],\n",
    "        'description':crime['attributes']['description'].strip()\n",
    "        }\n",
    "    crime_list.append(clean_crime)\n",
    "\n",
    "crime_severity={\n",
    "\"AUTOMOBILE THEFT\": 4,\n",
    "\"THEFT-MOTR VEH PARTS\": 2.5,\n",
    "\"OTHER THEFT\": 2.5,\n",
    "\"THEFT FROM MOTR VEHC\": 2,\n",
    "\"BURGLARY OF DWELLING\": 5,\n",
    "\"BURGLARY OF BUSINESS\": 4,\n",
    "\"ROBBERY PER AGG\": 8,\n",
    "\"ASSLT W/DNGRS WEAPON\": 6,\n",
    "\"ROBBERY INCLUDING AUTO THEFT\": 4,\n",
    "\"ROBBERY OF PERSON\": 4,\n",
    "\"BIKE THEFT\": 2,\n",
    "\"CSC - RAPE\": 9,\n",
    "\"SHOPLIFTING\": 4,\n",
    "\"2ND DEG DOMES ASLT\": 4,\n",
    "\"THEFT BY SWINDLE\": 3,\n",
    "\"DOMESTIC ASSAULT/STRANGULATION\": 4,\n",
    "\"ROBBERY OF BUSINESS\": 4,\n",
    "\"ASLT-SGNFCNT BDLY HM\": 4,\n",
    "\"ASLT4-LESS THAN SUBST HARM\": 4,\n",
    "\"THEFT FROM PERSON SNATCH/GRAB\": 4,\n",
    "\"ARSON\": 8,\n",
    "\"MURDER (GENERAL)\": 11,\n",
    "\"CSC - SODOMY\": 9,\n",
    "\"THEFT FROM BUILDING\": 4,\n",
    "\"3RD DEG DOMES ASLT\": 6,\n",
    "\"CSC - PENETRATE WITH OBJECT\": 9,\n",
    "\"ASLT-GREAT BODILY HM\": 9,\n",
    "\"OTHER VEHICLE THEFT\": 4,\n",
    "\"ASLT4-SUBST HARM OR WEAPON\": 6,\n",
    "\"OBS - PETTY THEFT\": 2,\n",
    "\"ON-LINE THEFT\": 2.5,\n",
    "\"FAIL TO PAY - TAXI/HOTEL/REST\": 2.5,\n",
    "\"ARSON-3RD DEGREE\": 3,\n",
    "\"OBS-CSCR - USE EXT 1, 2 OR 3\": 8,\n",
    "\"POCKET-PICKING\": 4,\n",
    "\"LOOTING\": 5,\n",
    "\"SCRAPPING-RECYCLING THEFT\": 2,\n",
    "\"1ST DEG DOMES ASLT\": 4,\n",
    "\"MURDER - 2ND DEGREE\": 11,\n",
    "\"HACKING - THEFT OF SERVICE\": 3,\n",
    "\"ARSON-1ST DEGREE\": 8,\n",
    "\"ACCESS/ALTER SYSTEM/NETWORK\": 3,\n",
    "\"ARSON-5TH DEGREE\": 3,\n",
    "\"GAS STATION DRIV-OFF\": 2.5,\n",
    "\"DO NOT USE\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents = pd.DataFrame(crime_list)\n",
    "\n",
    "#Set parameters for machine learning algorithm\n",
    "ClustersList=[50,100,200,250,500]\n",
    "PriorDaysList=[5,10,14,60,90,120]\n",
    "todayList=[datetime.date(2020,6,7),datetime.date(2020,11,4),datetime.date(2020,12,5),datetime.date(2020,10,19),datetime.date(2021,1,1),datetime.date(2021,2,11),datetime.date(2021,3,8),datetime.date(2020,7,23)]\n",
    "ScoreArray=[[0 for x in range(len(PriorDaysList))] for y in range(len(ClustersList))]\n",
    "\n",
    "for s1,Clusters in enumerate(ClustersList):\n",
    "\n",
    "    # Initialize and Fit KMeans Model\n",
    "    clusterer = KMeans(n_clusters=Clusters,random_state=42).fit(incidents[[\"centerLong\",\"centerLat\"]])\n",
    "\n",
    "    # Run Predictions\n",
    "    predictions = clusterer.predict(incidents[[\"centerLong\",\"centerLat\"]])\n",
    "\n",
    "    # Add column for clusters to incidents dataframe\n",
    "    incidents[\"cluster\"] = predictions\n",
    "\n",
    "    # Save Model using Pickle\n",
    "    # pickle.dump(clusterer, open(\"../models/clusterer.pkl\", \"wb\"))\n",
    "\n",
    "    \n",
    "    for s2,PriorDays in enumerate(PriorDaysList):\n",
    "        # today=datetime.date.today()\n",
    "        for today in todayList:\n",
    "            InitDay=today-datetime.timedelta(days=PriorDays)\n",
    "\n",
    "            #This assigns a danger value to each cluster that is not normalized\n",
    "            Cluster_Danger=[[0 for x in range(Clusters)] for y in range(PriorDays)]\n",
    "            #Only used for testing\n",
    "            Today_Danger=[0 for x in range(Clusters)]\n",
    "\n",
    "            for crime in crime_list:\n",
    "                MDY = [int(x) for x in crime[\"date\"].split(\"/\")]\n",
    "                date = datetime.date(MDY[2],MDY[0],MDY[1])\n",
    "                if date == InitDay:\n",
    "                    try:\n",
    "                        Cluster_Danger[0][clusterer.predict([[crime[\"centerLong\"],crime[\"centerLat\"]]])[0]]+=crime_severity[crime[\"description\"]]\n",
    "                    except KeyError:\n",
    "                        print(\"An error occured on the keys\")\n",
    "                        print(crime[\"description\"])\n",
    "                        print(\"\")\n",
    "                elif date > InitDay and date < today:\n",
    "                    num=int(str(date-InitDay).split(\",\")[0].split()[0])\n",
    "                    try:\n",
    "                        Cluster_Danger[num][clusterer.predict([[crime[\"centerLong\"],crime[\"centerLat\"]]])[0]]+=crime_severity[crime[\"description\"]]\n",
    "                    except KeyError:\n",
    "                        print(\"An error occured on the keys\")\n",
    "                        print(crime[\"description\"])\n",
    "                        print(\"\")\n",
    "            #Only used for testing\n",
    "                elif date == today:\n",
    "                    try:\n",
    "                        Today_Danger[clusterer.predict([[crime[\"centerLong\"],crime[\"centerLat\"]]])[0]]+=crime_severity[crime[\"description\"]]\n",
    "                    except KeyError:\n",
    "                        print(\"An error occured on the keys\")\n",
    "                        print(crime[\"description\"])\n",
    "                        print(\"\")\n",
    "\n",
    "\n",
    "            MaxDanger=0\n",
    "            for day in Cluster_Danger:\n",
    "                if MaxDanger<max(day):\n",
    "                    MaxDanger=max(day)\n",
    "            #This creates a normalized danger value for each cluster between 0 and 10\n",
    "            Normal_Cluster_Danger=[[] for y in range(PriorDays)]\n",
    "\n",
    "            for day in range (PriorDays):\n",
    "                for cluster in Cluster_Danger[day]:\n",
    "                    Normal_Cluster_Danger[day].append(cluster/MaxDanger*10)\n",
    "\n",
    "            #Only used for testing\n",
    "            Normal_Today_Danger=[]\n",
    "            for cluster in Today_Danger:\n",
    "                Normal_Today_Danger.append(math.ceil(cluster/MaxDanger*10))\n",
    "\n",
    "            Training_Data=[]\n",
    "            for d,day in enumerate(Normal_Cluster_Danger):\n",
    "                for c,cluster in enumerate(day):\n",
    "                    Training_Data.append({\n",
    "                        \"Day\": d,\n",
    "                        \"Cluster\": c,\n",
    "                        \"Danger\": cluster\n",
    "                    })\n",
    "            Training=pd.DataFrame(Training_Data)\n",
    "\n",
    "\n",
    "            #Only used for testing\n",
    "            Testing_Data=[]\n",
    "            for c,cluster in enumerate(Normal_Today_Danger):\n",
    "                Testing_Data.append({\n",
    "                    \"Day\": PriorDays,\n",
    "                    \"Cluster\": c,\n",
    "                    \"Danger\": cluster\n",
    "                })\n",
    "            Testing=pd.DataFrame(Testing_Data)\n",
    "\n",
    "            #Only used for testing\n",
    "            X_test = Testing[[\"Day\", \"Cluster\"]].values\n",
    "            y_test = Testing[\"Danger\"].values.reshape(-1, 1)\n",
    "\n",
    "            Predictions=[]\n",
    "            for cluster in range(Clusters):\n",
    "                CurrentTraining=Training.loc[Training['Cluster']==cluster]\n",
    "                # print(CurrentTraining.head())\n",
    "                #Setting up X and y to train our linear model\n",
    "                X_train = CurrentTraining[\"Day\"].values.reshape(-1, 1)\n",
    "                y_train = CurrentTraining[\"Danger\"].values.reshape(-1, 1)\n",
    "\n",
    "                #Create the model\n",
    "                model = LinearRegression()\n",
    "\n",
    "                #Fit the model to the training data. \n",
    "                model.fit(X_train, y_train)\n",
    "\n",
    "                # Use our model to predict a value\n",
    "                predicted = model.predict([[PriorDays]])\n",
    "                Predictions.append(min(max(math.ceil(predicted[0][0]),0),10))\n",
    "            Predictions=np.array(Predictions).reshape(-1,1)\n",
    "            SUM=0\n",
    "            for i,y in enumerate(Predictions):\n",
    "                SUM+=(y-y_test[i])**2\n",
    "            ScoreArray[s1][s2]+=math.sqrt(SUM/Clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del Cluster_Danger, MaxDanger, clean_crime, crime, crime_list, crime_severity, date, current_year, incidents, last_year, num, predictions, MDY, cluster, day\n",
    "# del Training_Data, Normal_Cluster_Danger, d, day, c, cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using 50 clusters and 5 prior days, the root mean square score is  \n17.973893697838978\n\nUsing 50 clusters and 10 prior days, the root mean square score is  \n14.423689795102796\n\nUsing 50 clusters and 14 prior days, the root mean square score is  \n14.193223401872599\n\nUsing 50 clusters and 60 prior days, the root mean square score is  \n10.24658178917826\n\nUsing 50 clusters and 90 prior days, the root mean square score is  \n9.327670747044468\n\nUsing 50 clusters and 120 prior days, the root mean square score is  \n8.509226846156874\n\nUsing 100 clusters and 5 prior days, the root mean square score is  \n16.017943081106825\n\nUsing 100 clusters and 10 prior days, the root mean square score is  \n13.105477024144514\n\nUsing 100 clusters and 14 prior days, the root mean square score is  \n12.769608301677316\n\nUsing 100 clusters and 60 prior days, the root mean square score is  \n9.487590544597602\n\nUsing 100 clusters and 90 prior days, the root mean square score is  \n9.499808940729768\n\nUsing 100 clusters and 120 prior days, the root mean square score is  \n9.091970341547423\n\nUsing 200 clusters and 5 prior days, the root mean square score is  \n14.20440052508631\n\nUsing 200 clusters and 10 prior days, the root mean square score is  \n12.228974006573214\n\nUsing 200 clusters and 14 prior days, the root mean square score is  \n11.590556596834773\n\nUsing 200 clusters and 60 prior days, the root mean square score is  \n9.197680884952142\n\nUsing 200 clusters and 90 prior days, the root mean square score is  \n8.858019141591408\n\nUsing 200 clusters and 120 prior days, the root mean square score is  \n8.774468132860719\n\nUsing 250 clusters and 5 prior days, the root mean square score is  \n13.590016591527613\n\nUsing 250 clusters and 10 prior days, the root mean square score is  \n11.746074411516414\n\nUsing 250 clusters and 14 prior days, the root mean square score is  \n11.37520710835647\n\nUsing 250 clusters and 60 prior days, the root mean square score is  \n8.88368203558369\n\nUsing 250 clusters and 90 prior days, the root mean square score is  \n8.724210417183546\n\nUsing 250 clusters and 120 prior days, the root mean square score is  \n8.733550117200648\n\nUsing 500 clusters and 5 prior days, the root mean square score is  \n11.191590472327073\n\nUsing 500 clusters and 10 prior days, the root mean square score is  \n9.534243031007154\n\nUsing 500 clusters and 14 prior days, the root mean square score is  \n9.152078716648388\n\nUsing 500 clusters and 60 prior days, the root mean square score is  \n7.913016046827741\n\nUsing 500 clusters and 90 prior days, the root mean square score is  \n8.004872771468603\n\nUsing 500 clusters and 120 prior days, the root mean square score is  \n8.040885182187502\n\n"
     ]
    }
   ],
   "source": [
    "for s1,Clusters in enumerate(ClustersList):\n",
    "    for s2, PriorDays in enumerate(PriorDaysList):\n",
    "        print(f\"Using {Clusters} clusters and {PriorDays} prior days, the root mean square score is  \")\n",
    "        print (ScoreArray[s1][s2])\n",
    "        print(\"\")\n"
   ]
  }
 ]
}